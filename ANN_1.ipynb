{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "# Import necessary libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sn\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\n# Load the dataset\ntrain = pd.read_csv('../Datasets/NB.csv')\ntrain['Fault'] = 0\ntest = pd.read_csv('../Datasets/IR - 7.csv')\ntest['Fault'] = 1\ndataset = train.append(test)\n\n# Prepare the input and output variables\nX = dataset.iloc[:, 0:2].values\ny = dataset.iloc[:, 2]\n\n# Split the dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n\n# Standardize the input variables\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n\n# Define the neural network model\nclassifier = Sequential()\nclassifier.add(Dense(units = 2, kernel_initializer = 'uniform', activation = 'relu', input_dim = 2))\nclassifier.add(Dense(units = 2, kernel_initializer = 'uniform', activation = 'relu'))\nclassifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n\n# Compile the model\nclassifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n\n# Train the model\nmodel = classifier.fit(X_train, y_train, batch_size = 1000, epochs = 100, shuffle = False)\n\n# Predict the output using the trained model\ny_pred = classifier.predict(X_test)\ny_pred = (y_pred > 0.5)\n\n# Evaluate the performance of the model\ncm = confusion_matrix(y_test, y_pred)\ncm_df = pd.DataFrame(cm, columns=['Normal', 'Inner Race (0.007\")'], index=['Normal', 'Inner Race (0.007\")'])\nplt.figure(figsize=(10,4))\nsn.set(font_scale=1.4)\nsn.heatmap(cm_df, annot=True, fmt='g')\nplt.title('Confusion matrix')\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.show()\n\nevaluation = classifier.evaluate(X_test, y_test)\nprint(\"Accuracy: {:.2f}%\".format(evaluation[1]*100))\n\ncr = classification_report(y_test, y_pred, target_names=['Normal', 'Inner Race (0.007\")'])\nprint(cr)\n\n# Count the number of anomalies in the predictions\nnormal, IR = cm\nanomalies = normal[1] + IR[0]\nprint(\"Anomalies detected: {}\".format(anomalies))\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}