{
  "metadata": {
    "language_info": {
      "name": ""
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "# importing packages\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.layers import Dense\nfrom keras.models import Sequential\n\n# importing datasets\nX = pd.read_csv('../Datasets/NB.csv')\nX['Fault'] = 0\n\ny = pd.read_csv('../Datasets/IR - 7.csv')\ny['Fault'] = 1\n\n# splitting data into train and test sets\nX_train, X_test = train_test_split(X, test_size=0.2, random_state=0)\ny_train, y_test = train_test_split(y, test_size=0.2, random_state=0)\n\n# concatenating train and test sets\ntrain = X_train.append(y_train)\ntest = X_test.append(y_test)\n\n# scaling the data\nscaler = MinMaxScaler()\ntrain = pd.DataFrame(scaler.fit_transform(train))\ntest = pd.DataFrame(scaler.transform(test))\n\n# defining the model\nact_func = 'relu'\nautoencoder = Sequential([\n    Dense(32, activation=act_func, kernel_initializer='glorot_uniform',\n          kernel_regularizer='l2', input_shape=(X_test.shape[1],)),\n    Dense(2, activation=act_func, kernel_initializer='glorot_uniform'),\n    Dense(32, activation=act_func, kernel_initializer='glorot_uniform'),\n    Dense(X_test.shape[1], kernel_initializer='glorot_uniform')\n])\nautoencoder.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n\n# fitting the model\nNUM_EPOCHS = 100\nBATCH_SIZE = 1000\nhistory = autoencoder.fit(train, train, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS,\n                          validation_split=0.1, verbose=1, shuffle=True)\n\n# plotting the loss curve\nplt.plot(history.history['loss'], 'b', label='Training loss')\nplt.plot(history.history['val_loss'], 'r', label='Validation loss')\nplt.legend(loc='upper right')\nplt.xlabel('Epochs')\nplt.ylabel('Loss, [mse]')\nplt.ylim([0, 0.05])\nplt.show()\n\n# evaluating the model on the training set\npred_train = autoencoder.predict(train)\nscored_train = pd.DataFrame()\nscored_train['Loss_mae'] = np.mean(np.abs(pred_train - train), axis=1)\nTH = 0.1\nscored_train['Threshold'] = TH\nscored_train['Anomaly'] = scored_train['Loss_mae'] > scored_train['Threshold']\nscored_train.plot(logy=True, figsize=(16, 4), xlim=[0, len(scored_train)])\n\n# identifying the anomalies in the training set\nanomalies = scored_train[scored_train['Anomaly'] == True]\nprint(anomalies)\nprint(anomalies.shape)\n\n# plotting the anomalies in the training set\nf, (ax1) = plt.subplots(figsize=(16, 4))\nax1.plot(scored_train.index, scored_train.Loss_mae, label='Loss(MAE)')\nax1.plot(scored_train.index, scored_train.Threshold, label='Threshold')\ng = sns.scatterplot(x=anomalies.index, y=anomalies.Loss_mae, label='anomaly', color='red')\ng.set(xlim=(0, len(scored_train.index)))\nplt.title('Anomalies')\nplt.legend()\n\n# evaluating the model on the test set\npred_test = autoencoder.predict(test)\nscored_test = pd.DataFrame()\nscored_test[\"Loss_mae\"] = np.mean(np.abs(pred_test - test), axis=1)\nscored_test[\"Threshold\"] = TH\nscored_test[\"Anomaly\"] = scored_test[\"Loss_mae\"] > scored_test[\"Threshold\"]\n\nscored_test\n\nscored_test[\"Loss_mae\"].mean()\n\nscored_test.plot(logy=True, figsize=(16, 4), xlim=[0, len(scored_test)])\n\nIR_anomalies = scored_test[scored_test[\"Anomaly\"] == True]\nprint(IR_anomalies)\nprint(IR_anomalies.shape)\n\nf, (ax2) = plt.subplots(figsize=(16, 4))\nax2.plot(scored_test.index, scored_test.Loss_mae, label=\"Loss(MAE)\")\nax2.plot(scored_test.index, scored_test.Threshold, label=\"Threshold\")\ng = sns.scatterplot(\n    x=IR_anomalies.index, y=IR_anomalies.Loss_mae, label=\"anomaly\", color=\"red\"\n)\ng.set(xlim=(0, len(scored_test.index)))\nplt.title(\"Anomalies\")\nplt.legend()\n\nprint(score[1])\n\nprint(\"Accuracy: {:.2f}%\".format(score[1] * 100))\n\nprint(\"Anomalies: {}\".format(IR_anomalies[\"Anomaly\"].count()))\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}